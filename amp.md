# 自动混合精度训练
**摘要：**传统上，深度学习训练通常使用32比特双精度浮点数FP32作为参数、梯度和中间Activation等的数据存储格式。使用FP32作为数据存储格式，每个数据需要4个字节的存储空间。为了节约显存消耗，业界提出使用16比特单精度浮点数FP16作为数据存储格式。使用FP16作为数据存储格式，每个数据仅需要2个字节的存储空间，相比于FP32可以节省一半的存储空间。除了降低显存消耗，FP16格式下，计算速度通常也更快，因此可以加速训练。
